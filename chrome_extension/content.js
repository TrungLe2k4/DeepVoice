// content.js ‚Äî DeepVoice Guard (realtime, no-echo, Flask-ready)

let dvRunning = false;
let audioCtx = null;
let workletReady = false;
let overlay = null;
// Map<HTMLMediaElement, { src, node }>
const sources = new Map();

// Observer theo d√µi media element
let mediaObserver = null;

// ƒê·∫£m b·∫£o AudioContext ch·ªâ start sau user gesture b√™n trong tab Meet
let pendingStart = false;
let gestureBound = false;

// Tr·∫°ng th√°i smoothing cho meter
let smooth = { p: 0, alpha: 0.2 };

// Throttle infer ƒë·ªÉ tr√°nh spam API / model
let lastInferTime = 0;
let inferBusy = false;
// ‚úÖ S·ª¨A: ph√¢n t√≠ch t·ªëi ƒëa 1 l·∫ßn m·ªói 2 gi√¢y
const INFER_INTERVAL_MS = 2000; // 2000ms = 2s gi·ªØa 2 l·∫ßn infer

// T·∫£i module g·ªçi API / fallback heuristic
import(chrome.runtime.getURL("model.js"))
  .then((mod) => {
    window.DVModel = mod;
  })
  .catch((e) => console.warn("DV model module error:", e));

/* ================= UI Overlay ================= */

function ensureOverlay() {
  if (overlay && document.contains(overlay)) return overlay;

  overlay = document.createElement("div");
  overlay.id = "dv-overlay";
  overlay.innerHTML = `
    <div class="dv-card">
      <div class="dv-row">
        <div class="dv-dot" id="dv-dot"></div>
        <div>
          <div class="dv-title">DeepVoice Guard</div>
          <div class="dv-sub" id="dv-sub">Gi√°m s√°t deepfake (realtime)</div>
        </div>
      </div>
      <div class="dv-meter">
        <div class="dv-meter-bar"><span id="dv-meter"></span></div>
        <div class="dv-meter-label">X√°c su·∫•t gi·∫£ m·∫°o</div>
      </div>
      <div class="dv-detail" id="dv-detail">ƒêang kh·ªüi ƒë·ªông...</div>
    </div>`;
  document.documentElement.appendChild(overlay);
  return overlay;
}

// ‚úÖ ƒê√É S·ª¨A: nh·∫≠n th√™m level t·ª´ backend
function setStatus(prob, reasons = [], level = null) {
  const dot = document.getElementById("dv-dot");
  const fill = document.getElementById("dv-meter");
  const det = document.getElementById("dv-detail");
  const sub = document.getElementById("dv-sub");
  if (!dot || !fill || !det) return;

  const p = Math.max(0, Math.min(1, Number(prob) || 0));
  smooth.p = smooth.alpha * p + (1 - smooth.alpha) * smooth.p;
  fill.style.width = smooth.p * 100 + "%";

  // Gh√©p l√Ω do g·ªçn g√†ng
  const reasonText =
    Array.isArray(reasons) && reasons.length ? reasons.join(" ¬∑ ") : "";

  // N·∫øu backend tr·∫£ level th√¨ ∆∞u ti√™n d√πng, kh√¥ng th√¨ suy ra t·ª´ prob
  let lv = level;
  if (!lv) {
    if (smooth.p >= 0.85) lv = "red";
    else if (smooth.p >= 0.6) lv = "amber";
    else lv = "green";
  }

  if (lv === "red") {
    dot.style.background = "#e53935";
    if (sub) sub.textContent = "M·ª©c r·ªßi ro: Cao";
    det.textContent = "üî¥ Nguy c∆° deepfake cao. " + reasonText;
  } else if (lv === "amber") {
    dot.style.background = "#fb8c00";
    if (sub) sub.textContent = "M·ª©c r·ªßi ro: Trung b√¨nh";
    det.textContent = "üü† C√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng. " + reasonText;
  } else {
    dot.style.background = "#43a047";
    if (sub) sub.textContent = "M·ª©c r·ªßi ro: Th·∫•p";
    det.textContent = "üü¢ An to√†n. " + reasonText;
  }
}

/* =============== Local heuristic fallback (n·∫øu kh√¥ng c√≥ model.js) =============== */
// Payload th·ª±c t·∫ø t·ª´ worklet:
// {
//   mfcc, lfcc,
//   pcen_stats: { mean[64], std[64] },
//   spec: { zcr, flat, rolloff, entropy, contrast },
//   prosody: { f0, jitter, shimmer, cpp },
//   meta: { sr, win, hop, snr }
// }

function localHeuristic(payload) {
  if (!payload) return 0;

  const spec = payload.spec || {};
  const pros = payload.prosody || {};
  const meta = payload.meta || {};

  const zcr = Number(spec.zcr || 0); // 0..1
  const flat = Number(spec.flat || 0); // 0..1
  const ent = Number(spec.entropy || 0); // 0..1
  const contr = Number(spec.contrast || 0); // ~0..?
  const snr = Number(meta.snr || 20); // 0..40 dB

  const f0 = Number(pros.f0 || 0);
  const jitter = Number(pros.jitter || 0); // 0..500 (scaled)
  const shimmer = Number(pros.shimmer || 0); // 0..500
  const cpp = Number(pros.cpp || 0); // 0..~20

  let score = 0;

  // 1) Gi·ªçng "qu√° m∆∞·ª£t/qu√° s·∫°ch": flat cao, entropy th·∫•p, SNR cao
  const pClean =
    0.6 * flat + 0.4 * (1 - ent) + 0.3 * Math.max(0, (snr - 25) / 15); // snr > 25 dB
  score += pClean * 0.5;

  // 2) Prosody "robot" ‚Äî jitter, shimmer r·∫•t th·∫•p nh∆∞ng CPP cao
  const jNorm = Math.min(1, jitter / 100);
  const shNorm = Math.min(1, shimmer / 100);
  const cppNorm = Math.min(1, cpp / 20);
  const pRobot = 0.5 * (1 - jNorm) + 0.3 * (1 - shNorm) + 0.2 * cppNorm;
  score += pRobot * 0.3;

  // 3) ZCR qu√° cao c≈©ng g·ª£i √Ω t√≠n hi·ªáu t·ªïng h·ª£p / nhi·ªÖu k·ª≥ l·∫°
  score += Math.max(0, (zcr - 0.15) * 2.0);

  // 4) N·∫øu F0 ngo√†i range gi·ªçng ng∆∞·ªùi (60‚Äì400), c·ªông nh·∫π
  if (f0 < 60 || f0 > 400) {
    score += 0.1;
  }

  return Math.max(0, Math.min(1, score));
}

/* ================= Core ================= */

async function start() {
  if (dvRunning) return;
  dvRunning = true;

  ensureOverlay();
  setStatus(0.02, ["ƒêang kh·ªüi ƒë·ªông..."]);

  // T·∫°o AudioContext
  if (!audioCtx) {
    try {
      audioCtx = new AudioContext({ latencyHint: "interactive" });
    } catch (e) {
      console.error("Cannot create AudioContext:", e);
      setStatus(0, ["Kh√¥ng t·∫°o ƒë∆∞·ª£c AudioContext"]);
      dvRunning = false;
      return;
    }
  }

  // Resume ‚Äî b·∫Øt bu·ªôc ph·∫£i n·∫±m trong user gesture (handler ph√≠a d∆∞·ªõi ƒë·∫£m b·∫£o)
  if (audioCtx.state === "suspended") {
    try {
      await audioCtx.resume();
    } catch (e) {
      console.warn("AudioContext resume blocked (no user gesture?):", e);
      setStatus(0, [
        "Tr√¨nh duy·ªát ƒëang ch·∫∑n AudioContext.",
        "H√£y click v√†o c·ª≠a s·ªï Meet ho·∫∑c b·∫≠t micro/loa r·ªìi b·∫≠t l·∫°i.",
      ]);
      dvRunning = false;
      return;
    }
  }

  // Load AudioWorklet
  if (!workletReady) {
    try {
      await audioCtx.audioWorklet.addModule(
        chrome.runtime.getURL("worklet-processor.js")
      );
      workletReady = true;
    } catch (e) {
      console.error("AudioWorklet addModule error:", e);
      setStatus(0, ["Kh√¥ng t·∫£i ƒë∆∞·ª£c Worklet"]);
      dvRunning = false;
      return;
    }
  }

  // ƒê·ª£i 1 frame ƒë·ªÉ DOM ·ªïn ƒë·ªãnh r·ªìi attach
  requestAnimationFrame(() => {
    attachToMediaTags();
    observeMediaTags();
    setStatus(0.05, ["ƒêang gi√°m s√°t..."]);
  });
}

function stop() {
  dvRunning = false;
  pendingStart = false;

  // Ng·∫Øt m·ªçi chain
  for (const [el, obj] of sources.entries()) {
    try {
      obj.src.disconnect();
    } catch (e) {}
    try {
      obj.node.port.close();
    } catch (e) {}
    try {
      obj.node.disconnect();
    } catch (e) {}
  }
  sources.clear();

  if (audioCtx) {
    try {
      audioCtx.close();
    } catch (e) {}
    audioCtx = null;
    workletReady = false;
  }

  // Ng·∫Øt observer n·∫øu c√≤n
  if (mediaObserver) {
    try {
      mediaObserver.disconnect();
    } catch (e) {}
    mediaObserver = null;
  }

  if (overlay) {
    overlay.remove();
    overlay = null;
  }
  smooth.p = 0;
}

/* ================= Audio chain ================= */

function makeChainFor(mediaEl) {
  if (!audioCtx || !workletReady) return null;

  let srcNode;
  try {
    srcNode = audioCtx.createMediaElementSource(mediaEl);
  } catch (e) {
    // N·∫øu ƒë√£ ƒë∆∞·ª£c t·∫°o source tr∆∞·ªõc ƒë√≥ (b·ªüi script kh√°c) s·∫Ω l·ªói
    console.warn("[DV] createMediaElementSource error:", e);
    return null;
  }

  const wnode = new AudioWorkletNode(audioCtx, "dv-analyzer", {
    numberOfInputs: 1,
    numberOfOutputs: 0, // kh√¥ng ph√°t l·∫°i ‚Üí tr√°nh echo
    processorOptions: { sampleRate: audioCtx.sampleRate },
  });

  // Ch·ªâ ph√¢n t√≠ch ‚Äî kh√¥ng n·ªëi ƒë·∫øn destination
  srcNode.connect(wnode);

  // Nh·∫≠n payload ƒë·∫∑c tr∆∞ng v√† g·ªçi API / heuristic (c√≥ throttle)
  wnode.port.onmessage = async (ev) => {
    const d = ev.data;
    if (!d || d.type !== "features") return;

    const now =
      typeof performance !== "undefined" && performance.now
        ? performance.now()
        : Date.now();

    // Throttle: ch·ªâ infer m·ªói INFER_INTERVAL_MS
    if (now - lastInferTime < INFER_INTERVAL_MS) {
      return;
    }
    // Kh√¥ng ch·∫°y ch·ªìng infer
    if (inferBusy) {
      return;
    }

    lastInferTime = now;
    inferBusy = true;

    const feats = d.payload;
    try {
      const model = window.DVModel;
      let prob = 0;
      let reasons = [];
      let level = null; // ‚úÖ nh·∫≠n level t·ª´ backend

      if (model?.sendFeatures) {
        const out = await model.sendFeatures(feats);
        prob = out?.prob_fused ?? out?.prob ?? 0;
        reasons = out?.reason || out?.reasons || [];
        level = out?.level || null;
      } else if (model?.predictProb) {
        prob = await model.predictProb(feats);
      } else {
        prob = localHeuristic(feats);
      }

      setStatus(prob, reasons, level);
    } catch (e) {
      // im l·∫∑ng ƒë·ªÉ kh√¥ng spam console
    } finally {
      inferBusy = false;
    }
  };

  return { src: srcNode, node: wnode };
}

function collectMediaElements() {
  // B·∫Øt c·∫£ audio l·∫´n video v√¨ Meet hay d√πng <video> ch·ª©a audio track
  return Array.from(document.querySelectorAll("audio, video"));
}

function attachToMediaTags() {
  if (!dvRunning) return;
  const medias = collectMediaElements();

  for (const m of medias) {
    if (sources.has(m)) continue;
    if (m.src || m.srcObject) {
      const ch = makeChainFor(m);
      if (ch) sources.set(m, ch);
    }
  }
}

function observeMediaTags() {
  if (mediaObserver) return;

  mediaObserver = new MutationObserver(() => {
    if (dvRunning) attachToMediaTags();
  });

  mediaObserver.observe(document.documentElement, {
    childList: true,
    subtree: true,
  });

  // ƒê·ªãnh k·ª≥ d·ªçn ph·∫ßn t·ª≠ media ƒë√£ b·ªã remove kh·ªèi DOM
  const gc = setInterval(() => {
    if (!dvRunning) {
      clearInterval(gc);
      if (mediaObserver) {
        try {
          mediaObserver.disconnect();
        } catch (e) {}
        mediaObserver = null;
      }
      return;
    }
    for (const [el, obj] of sources.entries()) {
      if (!document.contains(el)) {
        try {
          obj.src.disconnect();
        } catch (e) {}
        try {
          obj.node.port.close();
        } catch (e) {}
        try {
          obj.node.disconnect();
        } catch (e) {}
        sources.delete(el);
      }
    }
  }, 2000);
}

/* ================= User gesture binding ================= */

function bindGestureOnce() {
  if (gestureBound) return;
  gestureBound = true;

  const handler = () => {
    gestureBound = false;
    window.removeEventListener("pointerdown", handler, true);
    window.removeEventListener("keydown", handler, true);

    if (pendingStart && !dvRunning) {
      // g·ªçi start() tr·ª±c ti·∫øp trong handler ‚Üí AudioContext resume h·ª£p l·ªá
      start();
    }
  };

  window.addEventListener("pointerdown", handler, true);
  window.addEventListener("keydown", handler, true);
}

/* ================= Nh·∫≠n message t·ª´ background ================= */

chrome.runtime.onMessage.addListener((msg) => {
  if (!msg || !msg.type) return;

  // Th√¥ng b√°o nh·∫π khi user b·∫≠t ·ªü tab kh√¥ng ph·∫£i Meet (n·∫øu content.js c√≥ m·∫∑t)
  if (msg.type === "DV_INFO" && msg.message) {
    ensureOverlay();
    setStatus(0, [msg.message]);
    return;
  }

  // Flow ch√≠nh: background g·ª≠i DV_TOGGLE
  if (msg.type === "DV_TOGGLE") {
    if (dvRunning || pendingStart) {
      // ƒêang ON ‚Üí t·∫Øt
      pendingStart = false;
      if (dvRunning) {
        stop();
      } else {
        if (overlay) {
          overlay.remove();
          overlay = null;
        }
        smooth.p = 0;
      }
      return;
    }

    // ƒêang OFF ‚Üí chu·∫©n b·ªã b·∫≠t, ch·ªù user gesture trong tab
    pendingStart = true;
    ensureOverlay();
    setStatus(0.02, ["Nh·∫•p v√†o c·ª≠a s·ªï Meet ƒë·ªÉ b·∫Øt ƒë·∫ßu gi√°m s√°t..."]);
    bindGestureOnce();
    return;
  }

  // T√πy ch·ªçn: t∆∞∆°ng th√≠ch n·∫øu sau n√†y b·∫°n mu·ªën d√πng DV_START / DV_STOP
  if (msg.type === "DV_START") {
    pendingStart = true;
    ensureOverlay();
    setStatus(0.02, ["Nh·∫•p v√†o c·ª≠a s·ªï Meet ƒë·ªÉ b·∫Øt ƒë·∫ßu gi√°m s√°t..."]);
    bindGestureOnce();
    return;
  }

  if (msg.type === "DV_STOP") {
    pendingStart = false;
    if (dvRunning) {
      stop();
    } else {
      if (overlay) {
        overlay.remove();
        overlay = null;
      }
      smooth.p = 0;
    }
  }
});

// (Tu·ª≥ ch·ªçn) auto-start khi v√†o Meet ‚Äî KH√îNG khuy·∫øn kh√≠ch v√¨ s·∫Ω vi ph·∫°m AudioContext policy
// start();
